import streamlit as st
from PyPDF2 import PdfReader
from youtube_transcript_api import YouTubeTranscriptApi
from langchain_text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain.prompts import PromptTemplate
import os

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„ÙØ®Ø§Ù…Ø© ---
st.set_page_config(page_title="Ø®Ø¨ÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø°ÙƒÙŠ", page_icon="ğŸ§ ", layout="wide")

# --- 2. Ø³Ø·Ø± Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø¢Ù…Ù† (Ø§Ù„Ø°ÙŠ Ø³ÙŠÙ‚Ø±Ø£ Ù…Ù† Streamlit Secrets) ---
if "GOOGLE_API_KEY" in st.secrets:
    os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]
else:
    st.error("ÙŠØ±Ø¬Ù‰ Ø¥Ø¶Ø§ÙØ© GOOGLE_API_KEY ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Secrets ÙÙŠ Streamlit Cloud")

# --- 3. ÙˆØ¸Ø§Ø¦Ù Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ (PDF & YouTube) ---
def get_pdf_text(pdf_docs):
    text = ""
    for pdf in pdf_docs:
        try:
            pdf_reader = PdfReader(pdf)
            for page in pdf_reader.pages:
                extracted = page.extract_text()
                if extracted:
                    text += extracted
        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù PDF: {e}")
    return text

def get_youtube_text(video_url):
    try:
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ø±Ù Ø³ÙˆØ§Ø¡ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø·ÙˆÙŠÙ„ Ø£Ùˆ Ù‚ØµÙŠØ± (v= Ø£Ùˆ be/)
        if "v=" in video_url:
            video_id = video_url.split("v=")[1].split("&")[0]
        elif "youtu.be/" in video_url:
            video_id = video_url.split("youtu.be/")[1].split("?")[0]
        else:
            st.error("Ø±Ø§Ø¨Ø· Ø§Ù„ÙŠÙˆØªÙŠÙˆØ¨ ØºÙŠØ± ØµØ­ÙŠØ­")
            return None
            
        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['ar', 'en'])
        return " ".join([i['text'] for i in transcript])
    except Exception as e:
        st.error(f"Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¬Ù„Ø¨ Ø§Ù„Ù†Øµ Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ (Ù‚Ø¯ Ù„Ø§ ØªØªÙˆÙØ± ØªØ±Ø¬Ù…Ø© Ù…ØµØ§Ø­Ø¨Ø©): {e}")
        return None

# --- 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ ---
def get_vector_store(text):
    # ØªÙ‚Ø·ÙŠØ¹ Ø§Ù„Ù†Øµ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù‡Ù†Ø¯Ø³ÙŠ Ø¯Ù‚ÙŠÙ‚ Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… Ø¶ÙŠØ§Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    chunks = text_splitter.split_text(text)
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ù„Ù…ØªØ¬Ù‡Ø§Øª Ø¹Ø¯Ø¯ÙŠØ© (Embeddings)
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    
    # Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ®Ø²ÙŠÙ†Ù‡Ø§ Ù…Ø­Ù„ÙŠØ§Ù‹ ÙÙŠ Ø§Ù„Ø³ÙŠØ±ÙØ±
    vector_store = FAISS.from_texts(chunks, embedding=embeddings)
    vector_store.save_local("faiss_index")

def get_conversational_chain():
    # ØªØµÙ…ÙŠÙ… Ø§Ù„Ù€ Prompt Ø¨Ø£Ø³Ù„ÙˆØ¨ ÙŠÙ…Ù†Ø¹ Ø§Ù„Ù‡Ù„ÙˆØ³Ø©
    prompt_template = """
    Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰. 
    Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù‚Ø¯Ù… ÙÙ‚Ø· Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„. 
    Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ØŒ Ù‚Ù„ Ø¨ÙˆØ¶ÙˆØ­: "Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© ØºÙŠØ± Ù…Ø°ÙƒÙˆØ±Ø© ÙÙŠ Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø°ÙŠ Ø²ÙˆØ¯ØªÙ†ÙŠ Ø¨Ù‡".
    Ù„Ø§ ØªØ­Ø§ÙˆÙ„ Ø§Ø®ØªÙ„Ø§Ù‚ Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…Ù† Ø®Ø§Ø±Ø¬ Ø§Ù„Ù†Øµ.

    Ø§Ù„Ø³ÙŠØ§Ù‚:\n {context}?\n
    Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: \n{question}\n

    Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©:
    """
    model = ChatGoogleGenerativeAI(model="gemini-pro", temperature=0.3)
    prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
    return load_qa_chain(model, chain_type="stuff", prompt=prompt)

# --- 5. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Streamlit UI) ---
st.markdown("<h1 style='text-align: center;'>ğŸ§  Ø®Ø¨ÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ</h1>", unsafe_allow_html=True)
st.sidebar.title("ğŸ› ï¸ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ… ÙˆØ§Ù„Ù…ØµØ§Ø¯Ø±")

source_type = st.sidebar.radio("Ø§Ø®ØªØ± Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:", ("Ù…Ù„Ù PDF", "Ø±Ø§Ø¨Ø· YouTube"))

# ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù†Ø¯ Ø§Ù„Ø±ÙØ¹
if source_type == "Ù…Ù„Ù PDF":
    pdf_docs = st.sidebar.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ù€ PDF", accept_multiple_files=True, type=['pdf'])
    if st.sidebar.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª"):
        if pdf_docs:
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø°ÙƒÙŠØ©..."):
                raw_text = get_pdf_text(pdf_docs)
                if raw_text:
                    get_vector_store(raw_text)
                    st.sidebar.success("ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„! ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø¢Ù†.")
        else:
            st.sidebar.warning("ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„Ù Ø£ÙˆÙ„Ø§Ù‹.")

else:
    youtube_url = st.sidebar.text_input("Ø¶Ø¹ Ø±Ø§Ø¨Ø· ÙÙŠØ¯ÙŠÙˆ Ø§Ù„ÙŠÙˆØªÙŠÙˆØ¨:")
    if st.sidebar.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ"):
        if youtube_url:
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ø§Ù… Ù…Ù† Ø§Ù„ÙÙŠØ¯ÙŠÙˆ..."):
                raw_text = get_youtube_text(youtube_url)
                if raw_text:
                    get_vector_store(raw_text)
                    st.sidebar.success("ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ! ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø¢Ù†.")
        else:
            st.sidebar.warning("ÙŠØ±Ø¬Ù‰ ÙˆØ¶Ø¹ Ø§Ù„Ø±Ø§Ø¨Ø· Ø£ÙˆÙ„Ø§Ù‹.")

# --- 6. Ø§Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ---
user_question = st.text_input("ğŸ’¬ Ø§Ø³Ø£Ù„ Ø§Ù„Ø®Ø¨ÙŠØ± Ø¹Ù† Ø£ÙŠ ØªÙØµÙŠÙ„ ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø±ÙÙˆØ¹:")

if user_question:
    if os.path.exists("faiss_index"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…ØµØ§Ø¯Ø± ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©..."):
            embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
            # Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¢Ù…Ù† Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            new_db = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)
            docs = new_db.similarity_search(user_question)
            
            chain = get_conversational_chain()
            response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)
            
            st.markdown("### ğŸ¤– Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ø®Ø¨ÙŠØ±:")
            st.info(response["output_text"])
    else:
        st.warning("ÙŠØ±Ø¬Ù‰ ØªØ­Ù„ÙŠÙ„ Ù…ØµØ¯Ø± (PDF Ø£Ùˆ YouTube) Ù‚Ø¨Ù„ Ø·Ø±Ø­ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©.") 
                    
